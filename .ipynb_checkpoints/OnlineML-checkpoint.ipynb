{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [River - Python library for online machine learning](https://github.com/online-ml/river). \n",
    "\n",
    "It is the result of a merger between creme and scikit-multiflow. River's ambition is to be the go-to library for doing machine learning on streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Learning vs. Online Learning\n",
    "\n",
    "### Batch Learning\n",
    "\n",
    "Basic approach is the following:\n",
    "\n",
    "1. Collect some data, i.e. features $X$ and labels $Y$\n",
    "2. Train a model on $(X, Y)$, i.e. generate a function $f(X) \\approx Y$\n",
    "3. Save the model somewhere\n",
    "4. Load the model to make predictions\n",
    "\n",
    "Some drawbacks of batch learning are:\n",
    "\n",
    "- Models have to be retrained from scratch with new data\n",
    "- Models always \"lag\" behind\n",
    "- With increasing data, the comp. requirements increase\n",
    "- Batch models are **static** \n",
    "- Some locally developed features are not available in production/real-time\n",
    "\n",
    "Batch learning is popular mainly since it is taught at university, it is the main source of competitions on Kaggle, there are **libraries available** and one may achieve higher levels of accuracy in a direct comparison to online learning.\n",
    "\n",
    "Available libraries: [sklearn](https://scikit-learn.org/stable/), [pytorch](https://pytorch.org/), [tensorflow](https://tensorflow.org), etc. \n",
    "\n",
    "---\n",
    "\n",
    "### Online Learning\n",
    "\n",
    "Video sources: [Max Halford](https://www.youtube.com/watch?v=P3M6dt7bY9U), [Andrew Ng](https://www.youtube.com/watch?v=dnCzy_XKGbA)\n",
    "\n",
    "Literature sources: [Comprehensive Survey](https://arxiv.org/pdf/1802.02871.pdf)\n",
    "\n",
    "Different names for the same thing: **Incremental Learning**, *Sequential Learning*, **Iterative Learning**, *Out-of-core Learning*\n",
    "\n",
    "Basic features:\n",
    "\n",
    "- Data comes from a stream, i.e. in sequential order\n",
    "- Models learn 1 observation at a time\n",
    "- Observations do not have to be stored \n",
    "- Features and labels are dynamic \n",
    "- Models can dynamically adapt to new patterns in the data\n",
    "\n",
    "Available libraries: [river](https://github.com/online-ml/river), [vowpal wabbit](https://vowpalwabbit.org/)\n",
    "\n",
    "Usefull applications in\n",
    "\n",
    "- Time series forecasting \n",
    "- Spam filters and recommender systems\n",
    "- IoT\n",
    "- Basically, **anything event based** \n",
    "\n",
    "Algorithmic scheme of online learning:\n",
    "    <div style=\"background-color:rgba(0, 0, 0, 0.0670588); padding:5px 0;font-family:monospace;\">\n",
    "    <font color = \"red\">Forever do</font><br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; Get $(x,y)$ corresponding to new data.    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; Update $\\Theta$ using $(x,y)$ with SGD step:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\Theta_j := \\Theta_j - \\gamma \\nabla L$.<br>\n",
    "    </div>\n",
    "\n",
    "\n",
    "Major Drawbacks:\n",
    "\n",
    "- [Catastrophic inference](https://www.wikiwand.com/en/Catastrophic_interference): NN abruptly forgets what it has learned, first brought to the attention in 1989\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Deep Learning ODL\n",
    "\n",
    "based on [paper](https://www.ijcai.org/Proceedings/2018/0369.pdf)\n",
    "\n",
    "The main challenges for DNNs in the online learning setting are\n",
    "\n",
    "- vanishing gradients: DNNs loose the abiltiy to learn because gradients tend towards 0\n",
    "- diminishing feature reuse\n",
    "- saddle points\n",
    "- immense number of parameters to optimize\n",
    "- internal covariate shifts\n",
    "\n",
    "In the paper above, the authors extend the classic DNN such that each layer $h^i$ acts as output layer. The final prediction $F_t$ for data $t$ of the model is then given as linear combination of the predictions $f^i(x)$ of the individual layers. For parameter optimization, they introduce the so-called **Hedge Backpropagation**. Both is visualized in the paper in the following figure, in which $h^i$ is the respective layer of the DNN, i.e. nonlinear activation function of a linear combination of the inputs, $f^i$ is the respecitve prediction of the layer and $\\alpha_i$ is the respective weight.\n",
    "\n",
    "![Hedge Backpropagation](HBP.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Catastrophic Inference](https://www.wikiwand.com/en/Catastrophic_interference)\n",
    "\n",
    "Catastrophic interference, also known as catastrophic forgetting, is the tendency of an artificial neural network to completely and abruptly forget previously learned information upon learning new information. Catastrophic interference is an important issue to consider when creating connectionist models of memory. It was originally brought to the attention of the scientific community by research from McCloskey and Cohen (1989), and Ratcliff (1990). \n",
    "\n",
    "It is a radical manifestation of the **'sensitivity-stability' dilemma** or the **'stability-plasticity' dilemma**. Specifically, these problems refer to the challenge of making an artificial neural network that is sensitive to new information but not disrupted by. Lookup tables and connectionist networks lie on the opposite sides of the stability plasticity spectrum. The former (LuT) remains completely stable in the presence of new information but lacks the ability to generalize, i.e. to infer general principles from new inputs. On the other hand, neural networks like the standard backpropagation network can generalize to unseen inputs, but they are very sensitive to new information. Backpropagation models can be considered good models of human memory insofar as they mirror the human ability to generalize but these networks often exhibit less stability than human memory. Notably, these backpropagation networks are susceptible to catastrophic interference. \n",
    "\n",
    "The main cause of catastrophic interference seems to be overlap in the representations at the hidden layer of distributed neural networks. In a distributed representation, each input tends to create changes in the weights of many of the nodes. Catastrophic forgetting occurs because when many of the weights where \"knowledge is stored\" are changed, it is unlikely for prior knowledge to be kept intact. During sequential learning, the inputs become mixed, with the new inputs being superimposed on top of the old ones. Another way to conceptualize this is by visualizing learning as a movement through a weight space. This weight space can be likened to a spatial representation of all of the possible combinations of weights that the network could possess. When a network first learns to represent a set of patterns, it finds a point in the weight space that allows it to recognize all of those patterns. However, when the network then learns a new set of patterns, it will move to a place in the weight space for which the only concern is the recognition of the new patterns. To recognize both sets of patterns, the network must find a place in the weight space suitable for recognizing both the new and the old patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python37764bitthesisconda676ba76b19114f679caed66fc15b76ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
