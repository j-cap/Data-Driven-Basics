{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [River - Python library for online machine learning](https://github.com/online-ml/river). \n",
    "\n",
    "It is the result of a merger between creme and scikit-multiflow. River's ambition is to be the go-to library for doing machine learning on streaming data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Learning vs. Online Learning\n",
    "\n",
    "### Batch Learning\n",
    "\n",
    "Basic approach is the following:\n",
    "\n",
    "1. Collect some data, i.e. features $X$ and labels $Y$\n",
    "2. Train a model on $(X, Y)$, i.e. generate a function $f(X) \\approx Y$\n",
    "3. Save the model somewhere\n",
    "4. Load the model to make predictions\n",
    "\n",
    "Some drawbacks of batch learning are:\n",
    "\n",
    "- Models have to be retrained from scratch with new data\n",
    "- Models always \"lag\" behind\n",
    "- With increasing data, the comp. requirements increase\n",
    "- Batch models are **static** \n",
    "- Some locally developed features are not available in production/real-time\n",
    "\n",
    "Batch learning is popular mainly since it is taught at university, it is the main source of competitions on Kaggle, there are **libraries available** and one may achieve higher levels of accuracy in a direct comparison to online learning.\n",
    "\n",
    "---\n",
    "\n",
    "### Online Learning\n",
    "\n",
    "Video sources: [Max Halford](https://www.youtube.com/watch?v=P3M6dt7bY9U), [Andrew Ng](https://www.youtube.com/watch?v=dnCzy_XKGbA)\n",
    "\n",
    "Different names for the same thing: **Incremental Learning**, *Sequential Learning*, **Iterative Learning**, *Out-of-core Learning*\n",
    "\n",
    "Basic features:\n",
    "\n",
    "- Data comes from a stream, i.e. in sequential order\n",
    "- Models learn 1 observation at a time\n",
    "- Observations do not have to be stored \n",
    "- Features and labels are dynamic \n",
    "- Models can dynamically adapt to new patterns in the data\n",
    "\n",
    "Usefull applications in\n",
    "\n",
    "- Time series forecasting \n",
    "- Spam filters and recommender systems\n",
    "- IoT\n",
    "- Basically, **anything event based** \n",
    "\n",
    "Algorithmic scheme of online learning:\n",
    "    <div style=\"background-color:rgba(0, 0, 0, 0.0670588); padding:5px 0;font-family:monospace;\">\n",
    "    <font color = \"red\">Forever do</font><br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; Get $(x,y)$ corresponding to new data.    \n",
    "    &nbsp;&nbsp;&nbsp;&nbsp; Update $\\Theta$ using $(x,y)$ with SGD step:<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\Theta_j := \\Theta_j - \\gamma \\nabla L$.<br>\n",
    "    </div>\n",
    "\n",
    "\n",
    "Major Drawbacks:\n",
    "\n",
    "- [Catastrophic inference](https://www.wikiwand.com/en/Catastrophic_interference): NN abruptly forgets what it has learned, first brought to the attention in 1989\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Catastrophic Inference](https://www.wikiwand.com/en/Catastrophic_interference)\n",
    "\n",
    "Catastrophic interference, also known as catastrophic forgetting, is the tendency of an artificial neural network to completely and abruptly forget previously learned information upon learning new information. Catastrophic interference is an important issue to consider when creating connectionist models of memory. It was originally brought to the attention of the scientific community by research from McCloskey and Cohen (1989), and Ratcliff (1990). \n",
    "\n",
    "It is a radical manifestation of the 'sensitivity-stability' dilemma or the 'stability-plasticity' dilemma. Specifically, these problems refer to the challenge of making an artificial neural network that is sensitive to, but not disrupted by, new information. Lookup tables and connectionist networks lie on the opposite sides of the stability plasticity spectrum. The former (LuT) remains completely stable in the presence of new information but lacks the ability to generalize, i.e. infer general principles, from new inputs. On the other hand, connectionist networks like the standard backpropagation network can generalize to unseen inputs, but they are very sensitive to new information. Backpropagation models can be considered good models of human memory insofar as they mirror the human ability to generalize but these networks often exhibit less stability than human memory. Notably, these backpropagation networks are susceptible to catastrophic interference. This is an issue when modelling human memory, because unlike these networks, humans typically do not show catastrophic forgetting.\n",
    "\n",
    "The main cause of catastrophic interference seems to be overlap in the representations at the hidden layer of distributed neural networks. In a distributed representation, each input tends to create changes in the weights of many of the nodes. Catastrophic forgetting occurs because when many of the weights where \"knowledge is stored\" are changed, it is unlikely for prior knowledge to be kept intact. During sequential learning, the inputs become mixed, with the new inputs being superimposed on top of the old ones. Another way to conceptualize this is by visualizing learning as a movement through a weight space. This weight space can be likened to a spatial representation of all of the possible combinations of weights that the network could possess. When a network first learns to represent a set of patterns, it finds a point in the weight space that allows it to recognize all of those patterns. However, when the network then learns a new set of patterns, it will move to a place in the weight space for which the only concern is the recognition of the new patterns. To recognize both sets of patterns, the network must find a place in the weight space suitable for recognizing both the new and the old patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.975 (± 0.011)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "# Load the data\n",
    "dataset = datasets.load_breast_cancer()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "# Define the steps of the model\n",
    "model = pipeline.Pipeline([\n",
    "    ('scale', preprocessing.StandardScaler()),\n",
    "    ('lin_reg', linear_model.LogisticRegression(solver='lbfgs'))\n",
    "])\n",
    "\n",
    "# Define a determistic cross-validation procedure\n",
    "cv = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Compute the MSE values\n",
    "scorer = metrics.make_scorer(metrics.roc_auc_score)\n",
    "scores = model_selection.cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "\n",
    "# Display the average score and it's standard deviation\n",
    "print(f'ROC AUC: {scores.mean():.3f} (± {scores.std():.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001.0\n",
      "1326.0\n",
      "1203.0\n",
      "386.1\n",
      "1297.0\n",
      "477.1\n",
      "1040.0\n",
      "577.9\n",
      "519.8\n",
      "475.9\n",
      "797.8\n",
      "781.0\n",
      "1123.0\n",
      "782.7\n",
      "578.3\n",
      "658.8\n",
      "684.5\n",
      "798.8\n",
      "1260.0\n",
      "566.3\n",
      "520.0\n",
      "273.9\n",
      "704.4\n",
      "1404.0\n",
      "904.6\n",
      "912.7\n",
      "644.8\n",
      "1094.0\n",
      "732.4\n",
      "955.1\n",
      "1088.0\n",
      "440.6\n",
      "899.3\n",
      "1162.0\n",
      "807.2\n",
      "869.5\n",
      "633.0\n",
      "523.8\n",
      "698.8\n",
      "559.2\n",
      "563.0\n",
      "371.1\n",
      "1104.0\n",
      "545.2\n",
      "531.5\n",
      "1076.0\n",
      "201.9\n",
      "534.6\n",
      "449.3\n",
      "561.0\n",
      "427.9\n",
      "571.8\n",
      "437.6\n",
      "1033.0\n",
      "712.8\n",
      "409.0\n",
      "1152.0\n",
      "656.9\n",
      "527.2\n",
      "224.5\n",
      "311.9\n",
      "221.8\n",
      "645.7\n",
      "260.9\n",
      "499.0\n",
      "668.3\n",
      "269.4\n",
      "394.1\n",
      "250.5\n",
      "502.5\n",
      "1130.0\n",
      "244.0\n",
      "929.4\n",
      "584.1\n",
      "470.9\n",
      "817.7\n",
      "559.2\n",
      "1006.0\n",
      "1245.0\n",
      "506.3\n",
      "401.5\n",
      "520.0\n",
      "1878.0\n",
      "1132.0\n",
      "443.3\n",
      "1075.0\n",
      "648.2\n",
      "1076.0\n",
      "466.1\n",
      "651.9\n",
      "662.7\n",
      "728.2\n",
      "551.7\n",
      "555.1\n",
      "705.6\n",
      "1264.0\n",
      "451.1\n",
      "294.5\n",
      "412.6\n",
      "642.5\n",
      "582.7\n",
      "143.5\n",
      "458.7\n",
      "298.3\n",
      "336.1\n",
      "530.2\n",
      "412.5\n",
      "466.7\n",
      "1509.0\n",
      "396.5\n",
      "290.2\n",
      "480.4\n",
      "629.9\n",
      "334.2\n",
      "230.9\n",
      "438.6\n",
      "245.2\n",
      "682.5\n",
      "782.6\n",
      "982.0\n",
      "403.3\n",
      "1077.0\n",
      "1761.0\n",
      "640.7\n",
      "553.5\n",
      "588.7\n",
      "572.6\n",
      "1138.0\n",
      "674.5\n",
      "1192.0\n",
      "455.8\n",
      "748.9\n",
      "809.8\n",
      "761.7\n",
      "1075.0\n",
      "506.3\n",
      "423.6\n",
      "399.8\n",
      "678.1\n",
      "384.8\n",
      "288.5\n",
      "813.0\n",
      "398.0\n",
      "512.2\n",
      "355.3\n",
      "432.8\n",
      "432.0\n",
      "689.5\n",
      "640.1\n",
      "585.0\n",
      "519.4\n",
      "203.9\n",
      "300.2\n",
      "381.9\n",
      "538.9\n",
      "460.3\n",
      "963.7\n",
      "880.2\n",
      "448.6\n",
      "366.8\n",
      "419.8\n",
      "1157.0\n",
      "1214.0\n",
      "464.5\n",
      "1686.0\n",
      "690.2\n",
      "357.6\n",
      "886.3\n",
      "984.6\n",
      "685.9\n",
      "464.1\n",
      "565.4\n",
      "736.9\n",
      "372.7\n",
      "349.6\n",
      "227.2\n",
      "302.4\n",
      "832.9\n",
      "526.4\n",
      "508.8\n",
      "2250.0\n",
      "1311.0\n",
      "766.6\n",
      "402.0\n",
      "710.6\n",
      "317.5\n",
      "1041.0\n",
      "420.3\n",
      "428.9\n",
      "463.7\n",
      "609.9\n",
      "507.4\n",
      "288.1\n",
      "477.4\n",
      "671.4\n",
      "516.4\n",
      "588.9\n",
      "1024.0\n",
      "1148.0\n",
      "642.7\n",
      "461.0\n",
      "951.6\n",
      "1685.0\n",
      "597.8\n",
      "481.9\n",
      "716.6\n",
      "295.4\n",
      "904.3\n",
      "529.4\n",
      "725.5\n",
      "1290.0\n",
      "428.0\n",
      "2499.0\n",
      "948.0\n",
      "610.7\n",
      "578.9\n",
      "432.2\n",
      "321.2\n",
      "1230.0\n",
      "1223.0\n",
      "568.9\n",
      "561.3\n",
      "313.1\n",
      "761.3\n",
      "546.4\n",
      "641.2\n",
      "329.6\n",
      "684.5\n",
      "496.4\n",
      "503.2\n",
      "895.0\n",
      "395.7\n",
      "386.8\n",
      "1319.0\n",
      "279.6\n",
      "603.4\n",
      "1670.0\n",
      "1306.0\n",
      "623.9\n",
      "920.6\n",
      "575.3\n",
      "476.5\n",
      "389.4\n",
      "590.0\n",
      "1155.0\n",
      "337.7\n",
      "541.6\n",
      "512.2\n",
      "347.0\n",
      "406.3\n",
      "1364.0\n",
      "407.4\n",
      "1206.0\n",
      "928.2\n",
      "1169.0\n",
      "602.4\n",
      "1207.0\n",
      "713.3\n",
      "773.5\n",
      "744.9\n",
      "1288.0\n",
      "933.1\n",
      "947.8\n",
      "758.6\n",
      "928.3\n",
      "1419.0\n",
      "346.4\n",
      "561.0\n",
      "512.2\n",
      "344.9\n",
      "632.6\n",
      "388.0\n",
      "1491.0\n",
      "289.9\n",
      "998.9\n",
      "435.6\n",
      "396.6\n",
      "1102.0\n",
      "572.3\n",
      "587.4\n",
      "1138.0\n",
      "427.3\n",
      "1145.0\n",
      "805.1\n",
      "516.6\n",
      "489.0\n",
      "441.0\n",
      "515.9\n",
      "394.1\n",
      "396.0\n",
      "651.0\n",
      "687.3\n",
      "513.7\n",
      "432.7\n",
      "492.1\n",
      "582.7\n",
      "363.7\n",
      "431.1\n",
      "633.1\n",
      "334.2\n",
      "1217.0\n",
      "471.3\n",
      "1247.0\n",
      "334.3\n",
      "403.1\n",
      "417.2\n",
      "537.3\n",
      "246.3\n",
      "566.2\n",
      "530.6\n",
      "418.7\n",
      "664.9\n",
      "504.1\n",
      "409.1\n",
      "221.2\n",
      "481.6\n",
      "461.4\n",
      "1027.0\n",
      "244.5\n",
      "477.3\n",
      "324.2\n",
      "1274.0\n",
      "504.8\n",
      "1264.0\n",
      "457.9\n",
      "489.9\n",
      "616.5\n",
      "446.0\n",
      "813.7\n",
      "826.8\n",
      "793.2\n",
      "514.0\n",
      "387.3\n",
      "390.0\n",
      "464.4\n",
      "918.6\n",
      "514.3\n",
      "1092.0\n",
      "310.8\n",
      "1747.0\n",
      "641.2\n",
      "280.5\n",
      "373.9\n",
      "1194.0\n",
      "420.3\n",
      "321.6\n",
      "445.3\n",
      "668.7\n",
      "402.7\n",
      "426.7\n",
      "421.0\n",
      "758.6\n",
      "2010.0\n",
      "716.6\n",
      "384.6\n",
      "485.8\n",
      "512.0\n",
      "593.7\n",
      "241.0\n",
      "278.6\n",
      "491.9\n",
      "546.1\n",
      "496.6\n",
      "838.1\n",
      "552.4\n",
      "1293.0\n",
      "1234.0\n",
      "458.4\n",
      "1546.0\n",
      "1482.0\n",
      "840.4\n",
      "711.8\n",
      "1386.0\n",
      "1335.0\n",
      "579.1\n",
      "788.5\n",
      "338.3\n",
      "562.1\n",
      "580.6\n",
      "361.6\n",
      "386.3\n",
      "372.7\n",
      "447.8\n",
      "462.9\n",
      "541.8\n",
      "664.7\n",
      "462.0\n",
      "596.6\n",
      "392.0\n",
      "1174.0\n",
      "321.6\n",
      "234.3\n",
      "744.7\n",
      "1407.0\n",
      "446.2\n",
      "609.1\n",
      "558.1\n",
      "508.3\n",
      "378.2\n",
      "431.9\n",
      "994.0\n",
      "442.7\n",
      "525.2\n",
      "507.6\n",
      "469.1\n",
      "370.0\n",
      "800.0\n",
      "514.5\n",
      "991.7\n",
      "466.1\n",
      "399.8\n",
      "373.2\n",
      "268.8\n",
      "693.7\n",
      "719.5\n",
      "433.8\n",
      "271.2\n",
      "803.1\n",
      "495.0\n",
      "380.3\n",
      "409.7\n",
      "656.1\n",
      "408.2\n",
      "575.3\n",
      "289.7\n",
      "307.3\n",
      "333.6\n",
      "359.9\n",
      "381.1\n",
      "501.3\n",
      "685.0\n",
      "467.8\n",
      "1250.0\n",
      "1110.0\n",
      "673.7\n",
      "599.5\n",
      "509.2\n",
      "611.2\n",
      "592.6\n",
      "606.5\n",
      "371.5\n",
      "928.8\n",
      "585.9\n",
      "340.9\n",
      "990.0\n",
      "441.3\n",
      "981.6\n",
      "674.8\n",
      "659.7\n",
      "1384.0\n",
      "432.0\n",
      "1191.0\n",
      "442.5\n",
      "644.2\n",
      "492.9\n",
      "557.2\n",
      "415.1\n",
      "537.9\n",
      "520.2\n",
      "290.9\n",
      "930.9\n",
      "2501.0\n",
      "646.1\n",
      "412.7\n",
      "537.3\n",
      "542.9\n",
      "536.9\n",
      "286.3\n",
      "980.5\n",
      "408.8\n",
      "289.1\n",
      "449.9\n",
      "686.9\n",
      "465.4\n",
      "358.9\n",
      "506.9\n",
      "618.4\n",
      "599.4\n",
      "404.9\n",
      "815.8\n",
      "455.3\n",
      "602.9\n",
      "546.3\n",
      "571.1\n",
      "747.2\n",
      "476.7\n",
      "666.0\n",
      "1167.0\n",
      "420.5\n",
      "857.6\n",
      "466.5\n",
      "992.1\n",
      "1007.0\n",
      "477.3\n",
      "538.7\n",
      "680.9\n",
      "485.6\n",
      "480.1\n",
      "1068.0\n",
      "1320.0\n",
      "689.4\n",
      "595.9\n",
      "476.3\n",
      "1682.0\n",
      "248.7\n",
      "272.5\n",
      "453.1\n",
      "366.5\n",
      "819.8\n",
      "731.3\n",
      "426.0\n",
      "680.7\n",
      "556.7\n",
      "658.8\n",
      "701.9\n",
      "391.2\n",
      "1052.0\n",
      "1214.0\n",
      "493.1\n",
      "493.8\n",
      "257.8\n",
      "1841.0\n",
      "388.1\n",
      "571.0\n",
      "293.2\n",
      "221.3\n",
      "551.1\n",
      "468.5\n",
      "594.2\n",
      "445.2\n",
      "422.9\n",
      "416.2\n",
      "575.5\n",
      "1299.0\n",
      "365.6\n",
      "1308.0\n",
      "629.8\n",
      "406.4\n",
      "178.8\n",
      "170.4\n",
      "402.9\n",
      "656.4\n",
      "668.6\n",
      "538.4\n",
      "584.8\n",
      "573.2\n",
      "324.9\n",
      "320.8\n",
      "285.7\n",
      "361.6\n",
      "360.5\n",
      "378.4\n",
      "507.9\n",
      "264.0\n",
      "514.3\n",
      "321.4\n",
      "311.7\n",
      "271.3\n",
      "657.1\n",
      "403.5\n",
      "600.4\n",
      "386.0\n",
      "716.9\n",
      "1347.0\n",
      "1479.0\n",
      "1261.0\n",
      "858.1\n",
      "1265.0\n",
      "181.0\n"
     ]
    }
   ],
   "source": [
    "for xi, yi in zip(X, y):\n",
    "    xi = dict(zip(dataset.feature_names, xi))\n",
    "    print(xi[\"mean area\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean radius': 17.99,\n",
       " 'mean texture': 10.38,\n",
       " 'mean perimeter': 122.8,\n",
       " 'mean area': 1001.0,\n",
       " 'mean smoothness': 0.1184,\n",
       " 'mean compactness': 0.2776,\n",
       " 'mean concavity': 0.3001,\n",
       " 'mean concave points': 0.1471,\n",
       " 'mean symmetry': 0.2419,\n",
       " 'mean fractal dimension': 0.07871,\n",
       " 'radius error': 1.095,\n",
       " 'texture error': 0.9053,\n",
       " 'perimeter error': 8.589,\n",
       " 'area error': 153.4,\n",
       " 'smoothness error': 0.006399,\n",
       " 'compactness error': 0.04904,\n",
       " 'concavity error': 0.05373,\n",
       " 'concave points error': 0.01587,\n",
       " 'symmetry error': 0.03003,\n",
       " 'fractal dimension error': 0.006193,\n",
       " 'worst radius': 25.38,\n",
       " 'worst texture': 17.33,\n",
       " 'worst perimeter': 184.6,\n",
       " 'worst area': 2019.0,\n",
       " 'worst smoothness': 0.1622,\n",
       " 'worst compactness': 0.6656,\n",
       " 'worst concavity': 0.7119,\n",
       " 'worst concave points': 0.2654,\n",
       " 'worst symmetry': 0.4601,\n",
       " 'worst fractal dimension': 0.1189}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('thesis': conda)",
   "language": "python",
   "name": "python37664bitthesisconda4e23a8f720bf476ebd0f5fe3f9ef6962"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
